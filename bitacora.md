# Bit√°cora

Registro de cambios importantes del proyecto.

---

## 2025-09-05
- Edgar Calpa
- Inicio del proyecto monogr√°fico. Definici√≥n del tema: comparaci√≥n de EEGNet y ShallowConvNet aplicados a EEG con enfoque en biomarcadores de enfermedades neurodegenerativas.
- Creaci√≥n de repositorio inicial en GitHub.

## 2025-09-10
- Edgar Calpa
- Revisi√≥n bibliogr√°fica inicial sobre EEGNet y ShallowConvNet.
- Identificaci√≥n de datasets p√∫blicos (BCI Competition IV-2a) como punto de partida.

## 2025-09-15
- Edgar Calpa
- Organizaci√≥n preliminar de carpetas (`src/`, `data/`, `results/`).
- Creaci√≥n de `.gitignore` para excluir datasets y archivos temporales.

## 2025-09-20
- Edgar Calpa
- Configuraci√≥n de entorno en WSL2 con Python, PyTorch, MNE.
- Pruebas iniciales de carga de datos EEG.

## 2025-09-25
- Edgar Calpa
- Implementaci√≥n inicial del loader en `src/utils.py`.
- Lectura de archivos `.gdf` y `.mat` del BCI IV-2a.

## 2025-10-01
- Edgar Calpa
- A√±adida normalizaci√≥n trial-wise (z-score).
- Split train/val con `train_test_split`.

## 2025-10-05
- Edgar Calpa
- Integrado filtro bandpass opcional (4‚Äì40 Hz).
- Validaci√≥n con smoke test en `utils.py`.

## 2025-10-10
- Edgar Calpa
- Implementada segmentaci√≥n opcional en ventanas (`segment=True`).
- Actualizaci√≥n de `utils.py`.

## 2025-10-15
- Edgar Calpa
- A√±adidos modelos EEGNet y ShallowConvNet en `src/models.py`.

## 2025-10-20
- Edgar Calpa
- Creado script de entrenamiento `train_eegnet_bci_iv2a.py` (smoke test).
- Verificaci√≥n de p√©rdida decreciente en subset de 50 trials.

## 2025-10-25
- Edgar Calpa
- Creado script de entrenamiento `train_shallowconvnet_bci_iv2a.py` (smoke test).
- Validaci√≥n r√°pida en conjunto de validaci√≥n.

## 2025-11-01
- Edgar Calpa
- Documentaci√≥n en `README.md` con instrucciones de uso del pipeline BCI IV-2a.
- Actualizaci√≥n de bit√°cora con registros desde septiembre.

# Bit√°cora de desarrollo ‚Äì EEGNet_ShallowConvNet_Monografia

---

## üóìÔ∏è 05 de noviembre de 2025
- Se configur√≥ el entorno en WSL con soporte CUDA.  
- PyTorch estaba inicialmente en versi√≥n 2.0.1+cu117.  
- Se verific√≥ la detecci√≥n de la GPU NVIDIA GeForce GTX 1050.  

## üóìÔ∏è 06 de noviembre de 2025
- Se intent√≥ migrar a PyTorch cu122, pero no se encontraron binarios compatibles.  
- Se instal√≥ finalmente PyTorch 2.5.1+cu121 con CUDA 12.1 y cuDNN 9.1.  
- Se confirm√≥ que el entorno reconoce la GPU y corre en CUDA.  

## üóìÔ∏è 07 de noviembre de 2025
- Se instal√≥ MNE-Python 1.10.2 para lectura de archivos `.gdf`.  
- Se detect√≥ incompatibilidad con NumPy ‚â•1.24 (error `np.fromstring`).  
- Se resolvi√≥ bajando NumPy a 1.23.5.  
- Se ajust√≥ SciPy a 1.10.1 para compatibilidad con NumPy 1.23.5.  
- Se prob√≥ el loader (`utils.py`) y se confirm√≥ lectura correcta de los `.gdf`.  
- Se ejecut√≥ entrenamiento de ShallowConvNet en GPU:  
  - Epoch 1 ‚Üí Loss: 2.47  
  - Epoch 2 ‚Üí Loss: 1.25  
  - Validaci√≥n inicial ‚Üí Accuracy: 50%.  


## üóìÔ∏è 12 de noviembre de 2025
Se recre√≥ el entorno virtual .venv con Python 3.11 para evitar inconsistencias con Python 3.10.

Se instal√≥ exitosamente PyTorch 2.5.1+cu121, torchvision 0.20.1+cu121, torchaudio 2.5.1+cu121.

Se confirmaron versiones estables:

NumPy 1.26.4

SciPy 1.11.4

MNE 1.10.2

scikit-learn 1.7.2

matplotlib 3.10.7

pandas 2.3.3

Se verific√≥ la detecci√≥n de la GPU NVIDIA GeForce GTX 1050 con soporte CUDA disponible.

Se resolvi√≥ el problema de desincronizaci√≥n entre pip list y import torch al reinstalar todo en el .venv correcto.

El entorno qued√≥ listo para correr los scripts de entrenamiento (train_eegnet_bci_iv2a.py, train_shallowconvnet_bci_iv2a.py) sin errores de librer√≠as.


## üóìÔ∏è  2025-11-12  
**Modelo:** EEGNet  
**Sujeto:** A01  
**Dispositivo:** GPU (NVIDIA GTX 1050)  
**Dataset:** BCI Competition IV-2a  
**Segmentaci√≥n:** No  
**Filtro aplicado:** Band-pass 4‚Äì40 Hz  

### ‚öôÔ∏è Configuraci√≥n
- Epochs: 2  
- Batch size: 16  
- Learning rate: 0.001  
- Dropout: 0.25  
- Optimizer: Adam  

### üìä Resultados
- **Entrenamiento**
  - Epoch 1 ‚Üí Loss: 1.4420
  - Epoch 2 ‚Üí Loss: 1.1628
- **Validaci√≥n**
  - Loss final: 1.2149
  - Accuracy: 50.00 %

### üìù Observaciones
- Estratificaci√≥n: desactivada (clases con <2 muestras)  
- Loss decreciente, accuracy inicial moderada.  
- Pipeline estable, sin errores de ejecuci√≥n.


## üóìÔ∏è 2025-11-12 
Modelo: 
**ShallowConvNet Sujeto:** A01 
**Dispositivo:** GPU (NVIDIA GTX 1050) 
**Dataset:** BCI Competition IV-2a 
**Segmentaci√≥n:** No 
**Filtro aplicado:** Band-pass 4‚Äì40 Hz

‚öôÔ∏è Configuraci√≥n
Epochs: 2

Batch size: 16

Learning rate: 0.001

Dropout: 0.50

Optimizer: Adam

üìä Resultados
Entrenamiento

Epoch 1 ‚Üí Loss: 1.6835

Epoch 2 ‚Üí Loss: 0.8931

Validaci√≥n

Loss final: 6.1624

Accuracy: 25.00 %


## üìä Comparativa inicial ‚Äì Smoke tests (BCI IV‚Äë2a, sujeto A01)

| Modelo           | Epochs | Batch Size | Learning Rate | Dropout | Train Loss Final | Val Loss Final | Val Accuracy |
|------------------|--------|------------|---------------|---------|------------------|----------------|--------------|
| **EEGNet**       | 2      | 16         | 0.001         | 0.25    | 1.1628           | 1.2149         | 50.00 %      |
| **ShallowConvNet** | 2    | 16         | 0.001         | 0.50    | 0.8931           | 6.1624         | 25.00 %      |

### üìù Observaciones r√°pidas
- **EEGNet**: m√°s estable entre entrenamiento y validaci√≥n, accuracy inicial moderada.  
- **ShallowConvNet**: entren√≥ bien en train, pero se sobreajust√≥ y no generaliz√≥ (val_loss muy alto, accuracy baja).  

### üìà Gr√°ficas asociadas
![Loss Comparison](results/figuras/loss_comparison_2025-11-12.png)  
![Accuracy Comparison](results/figuras/accuracy_comparison_2025-11-12.png)
 

## üìä Comparativa ‚Äì Smoke tests con segmentaci√≥n (BCI IV‚Äë2a, sujeto A01)

<table>
  <thead>
    <tr>
      <th>Modelo</th>
      <th>Epochs</th>
      <th>Batch Size</th>
      <th>Learning Rate</th>
      <th>Dropout</th>
      <th>Segmentaci√≥n</th>
      <th>Train Loss Final</th>
      <th>Val Loss Final</th>
      <th>Val Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><b>EEGNet</b></td>
      <td>2</td>
      <td>16</td>
      <td>0.001</td>
      <td>0.25</td>
      <td style="color:green;">True ‚úÖ</td>
      <td>1.1655</td>
      <td>1.3394</td>
      <td style="color:green;"><b>50 %</b></td>
    </tr>
    <tr>
      <td><b>ShallowConvNet</b></td>
      <td>2</td>
      <td>16</td>
      <td>0.001</td>
      <td>0.50</td>
      <td style="color:green;">True ‚úÖ</td>
      <td>1.1225</td>
      <td style="color:red;"><b>6.8614</b></td>
      <td style="color:orange;"><b>50 %</b></td>
    </tr>
  </tbody>
</table>

### üìù Observaciones r√°pidas
- <b style="color:green;">EEGNet</b>: estable entre entrenamiento y validaci√≥n, accuracy inicial moderada.  
- <b style="color:red;">ShallowConvNet</b>: train loss baj√≥, pero validaci√≥n muy alta ‚Üí sobreajuste evidente.  
- Estratificaci√≥n desactivada (clases con <2 muestras).  
- Segmentaci√≥n activada gener√≥ m√°s muestras, pero con pocas epochs a√∫n no se observa mejora clara.  


### üìù Observaciones r√°pidas
- **EEGNet**: se mantiene estable entre entrenamiento y validaci√≥n, con accuracy inicial moderada.  
- **ShallowConvNet**: aunque el train loss baj√≥, la validaci√≥n sigue muy alta ‚Üí sobreajuste evidente.  
- Estratificaci√≥n desactivada (clases con <2 muestras).  
- Segmentaci√≥n activada gener√≥ m√°s muestras, pero con pocas epochs a√∫n no se observa mejora clara.  



üìí Bit√°cora de Entrenamientos ‚Äì BCI IV‚Äë2a
üß™ Smoke tests ‚Äì BCI IV‚Äë2a (sujeto A01)
## üóìÔ∏è 2025-11-14 
**Dispositivo:** GPU (GTX 1050) 
**Segmentaci√≥n:** No 
**Filtro:** Band-pass 4‚Äì40 Hz 
**Epochs:** 2 ‚Äî **Batch size:** 16 ‚Äî **LR:** 0.001 ‚Äî **Dropout:** EEGNet: 0.25 / ShallowConvNet: 0.50

üìä Resultados iniciales
Modelo	Train Loss	Val Loss	Accuracy
EEGNet	1.1628	1.2149	50.00 %
ShallowConvNet	0.8931	6.1624	25.00 %
Observaci√≥n: EEGNet m√°s estable; ShallowConvNet sobreajustado.

üß™ Smoke tests con segmentaci√≥n (segment=True)
Fecha: 2025-11-14 Segmentaci√≥n: Activada Estratificaci√≥n: Desactivada (clases <2 muestras)

Modelo	Train Loss	Val Loss	Accuracy
EEGNet	1.1655	1.3394	50.00 %
ShallowConvNet	1.1225	6.8614	50.00 %
Observaci√≥n: Segmentaci√≥n genera m√°s muestras, pero a√∫n no mejora rendimiento con pocas epochs.

üìä Comparativa global ‚Äì BCI IV‚Äë2a (sujetos A01‚ÄìA09)
Configuraci√≥n general:

Epochs: 2

Batch size: 16

Learning rate: 0.001

Filtro: Band-pass 4‚Äì40 Hz

Optimizer: Adam

üìà Promedio de rendimiento por modelo
Modelo	Val Accuracy promedio (%)	Val Loss promedio
EEGNet	52.78	1.32
ShallowConvNet	41.11	4.85
Observaciones globales:

EEGNet mantiene mejor estabilidad y generalizaci√≥n.

ShallowConvNet tiende al sobreajuste en validaci√≥n.

Segmentaci√≥n aumenta muestras, pero requiere m√°s epochs para mostrar beneficios claros.

üìà Gr√°ficas asociadas
loss_comparison_2025-11-14.png

accuracy_comparison_2025-11-14.png

A01_loss.png, A01_accuracy.png

global_accuracy.png, global_val_loss.png


üìù Observaciones
Estratificaci√≥n: desactivada (clases con <2 muestras).

Train loss decreciente, pero validaci√≥n muy alta ‚Üí indica sobreajuste o desbalance en el split.

Accuracy inicial baja, requiere m√°s datos y epochs para estabilizar.

Pipeline estable, sin errores de ejecuci√≥n.


üìå Pr√≥ximos pasos
Ejecutar smoke tests en ambos modelos (EEGNet y ShallowConvNet) con el dataset BCI IV‚Äë2a.

Documentar m√©tricas iniciales en results/.

Ajustar hiperpar√°metros y preparar entrenamiento completo en todos los sujetos.

Migrar pipeline al dataset cl√≠nico CN/MCI/AD + tau.


## üìÑ Bit√°cora de Proyecto ‚Äì Actualizaci√≥n 19/11/2025
üß© Etapa 1 ‚Äì Validaci√≥n t√©cnica inicial (BCI IV-2a)
‚úÖ Loader implementado (utils.py) con manejo de eventos repetidos y etiquetas fuera de rango.

‚úÖ Normalizaci√≥n trial-wise y filtro band-pass 4‚Äì40 Hz.

‚úÖ Modelos definidos (EEGNet y ShallowConvNet).

‚úÖ Smoke tests realizados en A01 (con y sin segmentaci√≥n).

‚úÖ Documentaci√≥n inicial en README.md y bitacora.md.

‚úÖ Segmentaci√≥n opcional aplicada en todos los sujetos (A01‚ÄìA09).

Conclusi√≥n: Etapa 1 cerrada.

üß© Etapa 2 ‚Äì Entrenamiento completo en dataset p√∫blico (BCI IV-2a)
‚úÖ Entrenamiento en todos los sujetos A01‚ÄìA09 con segmentaci√≥n y ‚â•50 epochs.

‚úÖ Comparativa entre EEGNet y ShallowConvNet (accuracy y val_loss).

‚úÖ Scripts de an√°lisis (analisis_metrics.py, gr√°ficas globales y por sujeto).

‚úÖ M√©tricas registradas en results/tablas/metrics.csv.

‚úÖ Documentar hiperpar√°metros en configs/bci_iv2a.yaml (pendiente, ya tenemos plantilla).

  üìÑ Configuraci√≥n usada ‚Äì 19/11/2025
Archivo: configs/bci_iv2a.yaml
- Epochs: 50
- Batch size: 32
- Learning rate: 0.001
- Optimizer: Adam
- EEGNet dropout: 0.25
- ShallowConvNet dropout: 0.50
- Segmentaci√≥n: activada


‚úÖ Consolidar bit√°cora con resultados globales y observaciones finales.

‚úÖ Entrenamientos largos (‚â•50 epochs) ejecutados y documentados.

Conclusi√≥n: Etapa 2 casi cerrada. Falta solo crear configs/bci_iv2a.yaml y a√±adir tabla global final en la bit√°cora.

üß© Etapa 3 ‚Äì Migraci√≥n al dataset cl√≠nico (CN/MCI/AD + tau)
‚ùå Organizaci√≥n de carpeta data/raw/CLINICO/.

‚ùå Loader para EEG + biomarcadores tau.

‚ùå Definir preprocesamiento cl√≠nico (filtros, normalizaci√≥n, segmentaci√≥n).

‚ö†Ô∏è Configuraci√≥n preliminar lista en configs/clinico.yaml (pendiente de uso).

Conclusi√≥n: Etapa 3 a√∫n no iniciada, pero infraestructura t√©cnica lista para migrar.

üß© Etapa 4 ‚Äì Integraci√≥n multimodal y an√°lisis final
‚ùå No iniciada, depende de la etapa cl√≠nica.

üìå Pr√≥ximos pasos
Cerrar Etapa 2

Crear archivo configs/bci_iv2a.yaml con hiperpar√°metros.

Actualizar bitacora.md con tabla global A01‚ÄìA09 y observaciones comparativas.

Preparar Etapa 3

Organizar carpeta data/raw/CLINICO/.

Implementar loader para EEG + tau.

Definir preprocesamiento cl√≠nico.

Etapa 4

Iniciar integraci√≥n multimodal una vez completada la etapa cl√≠nica.


## üìÑ Bit√°cora de Proyecto ‚Äì Actualizaci√≥n 28/11/2025
üß© Etapa 1 ‚Äì Validaci√≥n t√©cnica inicial (BCI IV-2a)
‚úÖ Loader implementado (utils.py) con manejo de eventos repetidos y etiquetas fuera de rango. 
‚úÖ Normalizaci√≥n trial-wise y filtro band-pass 4‚Äì40 Hz. 
‚úÖ Modelos definidos (EEGNet y ShallowConvNet). 
‚úÖ Smoke tests realizados en A01 (con y sin segmentaci√≥n). 
‚úÖ Documentaci√≥n inicial en README.md y bitacora.md.. 
‚úÖ Segmentaci√≥n opcional aplicada en todos los sujetos (A01‚ÄìA09).

Conclusi√≥n: Etapa 1 cerrada.

üß© Etapa 2 ‚Äì Entrenamiento completo en dataset p√∫blico (BCI IV-2a)
‚úÖ Entrenamiento en todos los sujetos A01‚ÄìA09 con segmentaci√≥n y ‚â•50 epochs. 
‚úÖ Comparativa entre EEGNet y ShallowConvNet (accuracy y val_loss). 
‚úÖ Scripts de an√°lisis (analisis_metrics.py, gr√°ficas globales y por sujeto). 
‚úÖ M√©tricas registradas en results/tablas/metrics.csv. 
‚ö†Ô∏è Documentar hiperpar√°metros en configs/bci_iv2a.yaml (pendiente, plantilla ya creada). 
‚úÖ Entrenamientos largos (‚â•50 epochs) ejecutados y documentados. 
‚úÖ Consolidar bit√°cora con resultados globales y observaciones finales.

Conclusi√≥n: Etapa 2 cerrada (solo falta formalizar configs/bci_iv2a.yaml y a√±adir tabla global final).

üß© Etapa 3 ‚Äì Migraci√≥n al dataset cl√≠nico (CN/MCI/AD + tau)
‚úÖ Carpeta data/raw/CLINICO/ organizada con index.csv completo (275k segmentos). 
‚úÖ Loader cl√≠nico (ClinicalEEGDataset) implementado y validado. 
‚úÖ Preprocesamiento definido: filtro band-pass 1‚Äì40 Hz, normalizaci√≥n trial-wise, segmentaci√≥n activada. 
‚úÖ Configuraci√≥n en configs/clinico.yaml lista y usada en corridas reales. 
‚úÖ Entrenamiento con EEGNet (10 √©pocas, batch_size=128, dropout=0.3, LR=0.0005) ‚Üí Val Acc: 91.27%. 
‚úÖ Entrenamiento con ShallowConvNet en curso (√©pocas 1‚Äì6 ya muestran mejora progresiva, Val Acc ~89%). 
‚úÖ M√©tricas cl√≠nicas registradas en results/tablas/metrics.csv. 
‚úÖ Modelo EEGNet guardado en results/modelos/EEGNet_Clinico.pth.

Conclusi√≥n: Etapa 3 en ejecuci√≥n activa. Ya hay resultados cl√≠nicos iniciales con EEGNet y ShallowConvNet, falta completar corridas largas y documentar comparativa.

üß© Etapa 4 ‚Äì Integraci√≥n multimodal y an√°lisis final
‚ùå No iniciada, depende de la consolidaci√≥n cl√≠nica. 
‚ö†Ô∏è Pendiente: extender index.csv con biomarcadores (tau, amyloid, scores) e integrar en pipeline multimodal.


üìå Pr√≥ximos pasos inmediatos
Formalizar configs/bci_iv2a.yaml y a√±adir tabla global A01‚ÄìA09 en bit√°cora.

Completar entrenamiento cl√≠nico con ShallowConvNet (‚â•10 √©pocas).

Documentar comparativa EEGNet vs ShallowConvNet en dataset cl√≠nico.

Generar gr√°ficas de evoluci√≥n (loss, accuracy) para ambos modelos.

Extender index.csv con biomarcadores y adaptar loader para multimodalidad.

‚úÖ En resumen: Etapa 1 y 2 cerradas, Etapa 3 en ejecuci√≥n activa con resultados cl√≠nicos iniciales, Etapa 4 a√∫n no iniciada.
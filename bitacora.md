# Bit√°cora

Registro de cambios importantes del proyecto.

---

## 2025-09-05
- Edgar Calpa
- Inicio del proyecto monogr√°fico. Definici√≥n del tema: comparaci√≥n de EEGNet y ShallowConvNet aplicados a EEG con enfoque en biomarcadores de enfermedades neurodegenerativas.
- Creaci√≥n de repositorio inicial en GitHub.

## 2025-09-10
- Edgar Calpa
- Revisi√≥n bibliogr√°fica inicial sobre EEGNet y ShallowConvNet.
- Identificaci√≥n de datasets p√∫blicos (BCI Competition IV-2a) como punto de partida.

## 2025-09-15
- Edgar Calpa
- Organizaci√≥n preliminar de carpetas (`src/`, `data/`, `results/`).
- Creaci√≥n de `.gitignore` para excluir datasets y archivos temporales.

## 2025-09-20
- Edgar Calpa
- Configuraci√≥n de entorno en WSL2 con Python, PyTorch, MNE.
- Pruebas iniciales de carga de datos EEG.

## 2025-09-25
- Edgar Calpa
- Implementaci√≥n inicial del loader en `src/utils.py`.
- Lectura de archivos `.gdf` y `.mat` del BCI IV-2a.

## 2025-10-01
- Edgar Calpa
- A√±adida normalizaci√≥n trial-wise (z-score).
- Split train/val con `train_test_split`.

## 2025-10-05
- Edgar Calpa
- Integrado filtro bandpass opcional (4‚Äì40 Hz).
- Validaci√≥n con smoke test en `utils.py`.

## 2025-10-10
- Edgar Calpa
- Implementada segmentaci√≥n opcional en ventanas (`segment=True`).
- Actualizaci√≥n de `utils.py`.

## 2025-10-15
- Edgar Calpa
- A√±adidos modelos EEGNet y ShallowConvNet en `src/models.py`.

## 2025-10-20
- Edgar Calpa
- Creado script de entrenamiento `train_eegnet_bci_iv2a.py` (smoke test).
- Verificaci√≥n de p√©rdida decreciente en subset de 50 trials.

## 2025-10-25
- Edgar Calpa
- Creado script de entrenamiento `train_shallowconvnet_bci_iv2a.py` (smoke test).
- Validaci√≥n r√°pida en conjunto de validaci√≥n.

## 2025-11-01
- Edgar Calpa
- Documentaci√≥n en `README.md` con instrucciones de uso del pipeline BCI IV-2a.
- Actualizaci√≥n de bit√°cora con registros desde septiembre.

# Bit√°cora de desarrollo ‚Äì EEGNet_ShallowConvNet_Monografia

---

## üóìÔ∏è 05 de noviembre de 2025
- Se configur√≥ el entorno en WSL con soporte CUDA.  
- PyTorch estaba inicialmente en versi√≥n 2.0.1+cu117.  
- Se verific√≥ la detecci√≥n de la GPU NVIDIA GeForce GTX 1050.  

## üóìÔ∏è 06 de noviembre de 2025
- Se intent√≥ migrar a PyTorch cu122, pero no se encontraron binarios compatibles.  
- Se instal√≥ finalmente PyTorch 2.5.1+cu121 con CUDA 12.1 y cuDNN 9.1.  
- Se confirm√≥ que el entorno reconoce la GPU y corre en CUDA.  

## üóìÔ∏è 07 de noviembre de 2025
- Se instal√≥ MNE-Python 1.10.2 para lectura de archivos `.gdf`.  
- Se detect√≥ incompatibilidad con NumPy ‚â•1.24 (error `np.fromstring`).  
- Se resolvi√≥ bajando NumPy a 1.23.5.  
- Se ajust√≥ SciPy a 1.10.1 para compatibilidad con NumPy 1.23.5.  
- Se prob√≥ el loader (`utils.py`) y se confirm√≥ lectura correcta de los `.gdf`.  
- Se ejecut√≥ entrenamiento de ShallowConvNet en GPU:  
  - Epoch 1 ‚Üí Loss: 2.47  
  - Epoch 2 ‚Üí Loss: 1.25  
  - Validaci√≥n inicial ‚Üí Accuracy: 50%.  


## üóìÔ∏è 12 de noviembre de 2025
Se recre√≥ el entorno virtual .venv con Python 3.11 para evitar inconsistencias con Python 3.10.

Se instal√≥ exitosamente PyTorch 2.5.1+cu121, torchvision 0.20.1+cu121, torchaudio 2.5.1+cu121.

Se confirmaron versiones estables:

NumPy 1.26.4

SciPy 1.11.4

MNE 1.10.2

scikit-learn 1.7.2

matplotlib 3.10.7

pandas 2.3.3

Se verific√≥ la detecci√≥n de la GPU NVIDIA GeForce GTX 1050 con soporte CUDA disponible.

Se resolvi√≥ el problema de desincronizaci√≥n entre pip list y import torch al reinstalar todo en el .venv correcto.

El entorno qued√≥ listo para correr los scripts de entrenamiento (train_eegnet_bci_iv2a.py, train_shallowconvnet_bci_iv2a.py) sin errores de librer√≠as.


**Fecha:** 2025-11-12  
**Modelo:** EEGNet  
**Sujeto:** A01  
**Dispositivo:** GPU (NVIDIA GTX 1050)  
**Dataset:** BCI Competition IV-2a  
**Segmentaci√≥n:** No  
**Filtro aplicado:** Band-pass 4‚Äì40 Hz  

### ‚öôÔ∏è Configuraci√≥n
- Epochs: 2  
- Batch size: 16  
- Learning rate: 0.001  
- Dropout: 0.25  
- Optimizer: Adam  

### üìä Resultados
- **Entrenamiento**
  - Epoch 1 ‚Üí Loss: 1.4420
  - Epoch 2 ‚Üí Loss: 1.1628
- **Validaci√≥n**
  - Loss final: 1.2149
  - Accuracy: 50.00 %

### üìù Observaciones
- Estratificaci√≥n: desactivada (clases con <2 muestras)  
- Loss decreciente, accuracy inicial moderada.  
- Pipeline estable, sin errores de ejecuci√≥n.


**Fecha:** 2025-11-12 Modelo: 
**ShallowConvNet Sujeto:** A01 
**Dispositivo:** GPU (NVIDIA GTX 1050) 
**Dataset:** BCI Competition IV-2a 
**Segmentaci√≥n:** No 
**Filtro aplicado:** Band-pass 4‚Äì40 Hz

‚öôÔ∏è Configuraci√≥n
Epochs: 2

Batch size: 16

Learning rate: 0.001

Dropout: 0.50

Optimizer: Adam

üìä Resultados
Entrenamiento

Epoch 1 ‚Üí Loss: 1.6835

Epoch 2 ‚Üí Loss: 0.8931

Validaci√≥n

Loss final: 6.1624

Accuracy: 25.00 %


## üìä Comparativa inicial ‚Äì Smoke tests (BCI IV‚Äë2a, sujeto A01)

| Modelo           | Epochs | Batch Size | Learning Rate | Dropout | Train Loss Final | Val Loss Final | Val Accuracy |
|------------------|--------|------------|---------------|---------|------------------|----------------|--------------|
| **EEGNet**       | 2      | 16         | 0.001         | 0.25    | 1.1628           | 1.2149         | 50.00 %      |
| **ShallowConvNet** | 2    | 16         | 0.001         | 0.50    | 0.8931           | 6.1624         | 25.00 %      |

### üìù Observaciones r√°pidas
- **EEGNet**: m√°s estable entre entrenamiento y validaci√≥n, accuracy inicial moderada.  
- **ShallowConvNet**: entren√≥ bien en train, pero se sobreajust√≥ y no generaliz√≥ (val_loss muy alto, accuracy baja).  

### üìà Gr√°ficas asociadas
![Loss Comparison](results/figuras/loss_comparison_2025-11-12.png)  
![Accuracy Comparison](results/figuras/accuracy_comparison_2025-11-12.png)
 

## üìä Comparativa ‚Äì Smoke tests con segmentaci√≥n (BCI IV‚Äë2a, sujeto A01)

<table>
  <thead>
    <tr>
      <th>Modelo</th>
      <th>Epochs</th>
      <th>Batch Size</th>
      <th>Learning Rate</th>
      <th>Dropout</th>
      <th>Segmentaci√≥n</th>
      <th>Train Loss Final</th>
      <th>Val Loss Final</th>
      <th>Val Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><b>EEGNet</b></td>
      <td>2</td>
      <td>16</td>
      <td>0.001</td>
      <td>0.25</td>
      <td style="color:green;">True ‚úÖ</td>
      <td>1.1655</td>
      <td>1.3394</td>
      <td style="color:green;"><b>50 %</b></td>
    </tr>
    <tr>
      <td><b>ShallowConvNet</b></td>
      <td>2</td>
      <td>16</td>
      <td>0.001</td>
      <td>0.50</td>
      <td style="color:green;">True ‚úÖ</td>
      <td>1.1225</td>
      <td style="color:red;"><b>6.8614</b></td>
      <td style="color:orange;"><b>50 %</b></td>
    </tr>
  </tbody>
</table>

### üìù Observaciones r√°pidas
- <b style="color:green;">EEGNet</b>: estable entre entrenamiento y validaci√≥n, accuracy inicial moderada.  
- <b style="color:red;">ShallowConvNet</b>: train loss baj√≥, pero validaci√≥n muy alta ‚Üí sobreajuste evidente.  
- Estratificaci√≥n desactivada (clases con <2 muestras).  
- Segmentaci√≥n activada gener√≥ m√°s muestras, pero con pocas epochs a√∫n no se observa mejora clara.  


### üìù Observaciones r√°pidas
- **EEGNet**: se mantiene estable entre entrenamiento y validaci√≥n, con accuracy inicial moderada.  
- **ShallowConvNet**: aunque el train loss baj√≥, la validaci√≥n sigue muy alta ‚Üí sobreajuste evidente.  
- Estratificaci√≥n desactivada (clases con <2 muestras).  
- Segmentaci√≥n activada gener√≥ m√°s muestras, pero con pocas epochs a√∫n no se observa mejora clara.  


üìù Observaciones
Estratificaci√≥n: desactivada (clases con <2 muestras).

Train loss decreciente, pero validaci√≥n muy alta ‚Üí indica sobreajuste o desbalance en el split.

Accuracy inicial baja, requiere m√°s datos y epochs para estabilizar.

Pipeline estable, sin errores de ejecuci√≥n.


üìå Pr√≥ximos pasos
Ejecutar smoke tests en ambos modelos (EEGNet y ShallowConvNet) con el dataset BCI IV‚Äë2a.

Documentar m√©tricas iniciales en results/.

Ajustar hiperpar√°metros y preparar entrenamiento completo en todos los sujetos.

Migrar pipeline al dataset cl√≠nico CN/MCI/AD + tau.
